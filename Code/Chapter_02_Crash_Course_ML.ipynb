{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab380154",
   "metadata": {},
   "source": [
    "# CPE 487 587 Deep Learning for Engineering Applications\n",
    "## Instructor: Rahul Bhadani\n",
    "## Chapter 1: Crash Course in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1f70c",
   "metadata": {},
   "source": [
    "# 0. Python Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a245753",
   "metadata": {},
   "source": [
    "### 1. **Numeric Data Types**\n",
    "* integer (int) represents whole number\n",
    "* floating point type (float) represents decimal numbers\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "462e7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type of variable age =  <class 'int'>\n",
      "data type of variable pi =  <class 'float'>\n",
      "data type of variable temperature =  <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "age = 23  #int\n",
    "pi = 3.14 #float\n",
    "temperature = -5.5 #float\n",
    "\n",
    "print(\"data type of variable age = \", type(age))\n",
    "print(\"data type of variable pi = \", type(pi))\n",
    "print(\"data type of variable temperature = \", type(temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ea286",
   "metadata": {},
   "source": [
    "### 2. **String Data Type**\n",
    "  string (str) represents sequence of characters enclosed by double quotes or single quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca70f119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type of the variable name =  <class 'str'>\n",
      "data type of the variable greeting =  <class 'str'>\n",
      "data type of the variable address =  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "name = \"Alice\"\n",
    "greeting = 'Hello'\n",
    "address = \"123 Main St\"\n",
    "\n",
    "print(\"data type of the variable name = \",type(name))\n",
    "print(\"data type of the variable greeting = \",type(greeting))\n",
    "print(\"data type of the variable address = \",type(address))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4985bd11",
   "metadata": {},
   "source": [
    "### 3. **Boolean Type**\n",
    "\n",
    "Boolean (bool) represents a boolean value, either True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672308a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type of the variable is_student =  <class 'bool'>\n",
      "data type of the variable has_license =  <class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "is_student = True\n",
    "has_license = False\n",
    "\n",
    "print(\"data type of the variable is_student = \",type(is_student))\n",
    "print(\"data type of the variable has_license = \",type(has_license))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872ae192",
   "metadata": {},
   "source": [
    "### 4. **List**\n",
    "    \n",
    "'list' represents an ordered, mutable collection of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3664470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1, 2, 3, 4]\n",
    "mixed_list = [12, \"Hello\", True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8952354",
   "metadata": {},
   "source": [
    "### 5. **Tuple**\n",
    "\n",
    "'tuple' represents an ordered, immutable collection of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ('red', 'green', 'yellow', 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1149d",
   "metadata": {},
   "source": [
    "### 6. **Dictionary**\n",
    "\n",
    "'dict' represents a collection of key-value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888ed6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is John. I am 30 years old and I live at Pitt.\n"
     ]
    }
   ],
   "source": [
    "person = {'name':'John','age':30,'city':'Pitt'}\n",
    "\n",
    "print(f\"Hello my name is {person['name']}. I am {person['age']} years old and I live at {person['city']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58210dc0",
   "metadata": {},
   "source": [
    "### 7. **Set**\n",
    "\n",
    "'set' represents an unordered, immutable collection of elements that are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de17148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "unique_numbers = {1,2,3,3,3,3,4,5}\n",
    "\n",
    "print(unique_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede75f2",
   "metadata": {},
   "source": [
    "### 8. **NoneType**\n",
    "\n",
    "It represents the absence of a value, which similar to null in other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58207cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda7e4a0",
   "metadata": {},
   "source": [
    "## LOGICAL STATEMENTS AND LOOPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b3cf1",
   "metadata": {},
   "source": [
    "### 1. **if and else statement :**\n",
    "\n",
    "It allows conditional execution of code based on the evaluation of a given condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7c05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "num = 10\n",
    "if num > 0:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Non-positive\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac38b5",
   "metadata": {},
   "source": [
    "### 2. **and, or, and not operators:**\n",
    "\n",
    "  These operators are used for combining conditions and negating them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e9a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both conditions are true\n",
      "At least one condition is true\n",
      "x is not equal to 0\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "y = 10\n",
    "if x > 0 and y < 20:\n",
    "    print(\"Both conditions are true\")\n",
    "if x > 0 or y > 20:\n",
    "    print(\"At least one condition is true\")\n",
    "if not x == 0:\n",
    "    print(\"x is not equal to 0\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcd30cf",
   "metadata": {},
   "source": [
    "### 3. **for  loop:**\n",
    "\n",
    "It iterates over a sequence (e.g., list, tuple, string) and performs actions for each element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5db4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "banana\n",
      "cherry\n"
     ]
    }
   ],
   "source": [
    "fruits = [\"apple\", \"banana\",\"cherry\"]\n",
    "\n",
    "for fruit in fruits:\n",
    "    print(fruit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b64e01",
   "metadata": {},
   "source": [
    "### 4. **while loop:**\n",
    "\n",
    "It repeatedly executes a block of code as long as a given condition is true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f020948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count is: 0\n",
      "Count is: 1\n",
      "Count is: 2\n",
      "Count is: 3\n",
      "Count is: 4\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "while count < 5:\n",
    "    print(\"Count is:\", count)\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6417da62",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef1eda6",
   "metadata": {},
   "source": [
    "### 1. **Built-in Functions**\n",
    "\n",
    "print(), min(), max(), len(), range(), type() etc.\n",
    "\n",
    "  These functions are already provided as part of python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88ed4766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "fruits = [\"apple\", \"banana\",\"cherry\"]\n",
    "print(len(fruits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077b0b1e",
   "metadata": {},
   "source": [
    "### 2.  **Built-in Methods**\n",
    "\n",
    "  Data types in python have “methods” associated with them - functions specifically designed to operate on instances of that data type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079df6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name in upper case =  JOHN\n",
      "List after appending [1, 2, 3, 4, 5]\n",
      "Keys of the dictionary person dict_keys(['name', 'age', 'city'])\n"
     ]
    }
   ],
   "source": [
    "name = \"john\"\n",
    "print(\"Name in upper case = \", name.upper())\n",
    "\n",
    "l = [1,2,3,4]\n",
    "l.append(5)\n",
    "print(\"List after appending\",l)\n",
    "\n",
    "person = {'name':'John','age':30,'city':'Pitt'}\n",
    "print(\"Keys of the dictionary person\", person.keys())\n",
    "\n",
    "# for more methods explore https://www.w3schools.com/python/python_ref_functions.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd2a960",
   "metadata": {},
   "source": [
    "### 3. **User Defined Functions**\n",
    "\n",
    "  Functions we define ourselves to perform specific task.\n",
    "\n",
    "  User-defined functions help to decompose a large program into small segments which makes the program easy to understand, maintain and debug.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd130641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumb! 3 is always less than 5\n"
     ]
    }
   ],
   "source": [
    "def print_something():\n",
    "    if 3 < 5:\n",
    "        print(\"Dumb! 3 is always less than 5\")\n",
    "    else:\n",
    "        print(\"I can never reach here\")\n",
    "    return\n",
    "\n",
    "print_something()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47d1d5",
   "metadata": {},
   "source": [
    "# 1. Numpy fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930e5e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 6\n",
      "ndim: 0\n",
      "shape: ()\n",
      "size: 1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Basic array types\n",
    "# Scalar (0‑D)\n",
    "x = np.array(6)\n",
    "print(\"x:\", x)\n",
    "print(\"ndim:\", x.ndim)\n",
    "print(\"shape:\", x.shape)\n",
    "print(\"size:\", x.size)\n",
    "print(\"dtype:\", x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f86d31ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v: [1 2 3]\n",
      "ndim: 1\n",
      "shape: (3,)\n",
      "size: 3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vector (1‑D)\n",
    "v = np.array([1, 2, 3])\n",
    "print(\"v:\", v)\n",
    "print(\"ndim:\", v.ndim)\n",
    "print(\"shape:\", v.shape)\n",
    "print(\"size:\", v.size)\n",
    "print(\"dtype:\", v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ca855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "ndim: 2\n",
      "shape: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "# Matrix (2‑D)\n",
    "M = np.array([[1, 2, 3],\n",
    "            [4, 5, 6]])\n",
    "print(\"M:\\n\", M)\n",
    "print(\"ndim:\", M.ndim)\n",
    "print(\"shape:\", M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e2aa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T shape: (2, 3, 4)\n",
      "ndim: 3\n"
     ]
    }
   ],
   "source": [
    "# 3‑D tensor\n",
    "T = np.arange(2*3*4).reshape(2, 3, 4)\n",
    "print(\"T shape:\", T.shape)\n",
    "print(\"ndim:\", T.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db71c0b",
   "metadata": {},
   "source": [
    "Python is dynamically typed, but NumPy arrays have a fixed data type. If we are not careful, we can lose precision when working with floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d553fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ints dtype: int64\n",
      "floats_default dtype: float64\n",
      "floats32 dtype: float32\n"
     ]
    }
   ],
   "source": [
    "ints = np.array([1, 2, 3])\n",
    "floats_default = np.array([1.2, 2.5, 3.8])\n",
    "floats32 = np.array([1.2, 2.5, 3.8], dtype=np.float32)\n",
    "\n",
    "print(\"ints dtype:\", ints.dtype)\n",
    "print(\"floats_default dtype:\", floats_default.dtype)\n",
    "print(\"floats32 dtype:\", floats32.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e27dc",
   "metadata": {},
   "source": [
    "NumPy provides helper functions to quickly build common arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3812b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros:\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "ones:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "identity matrix:\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"zeros:\")\n",
    "print(np.zeros((2, 3)))\n",
    "\n",
    "print(\"\\nones:\")\n",
    "print(np.ones((2, 3)))\n",
    "\n",
    "print(\"\\nidentity matrix:\")\n",
    "print(np.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7686690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arange 0..9: [0 1 2 3 4 5 6 7 8 9]\n",
      "linspace 0..1 (5 points): [0.   0.25 0.5  0.75 1.  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"arange 0..9:\", np.arange(10))\n",
    "print(\"linspace 0..1 (5 points):\", np.linspace(0, 1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b1d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random normal (2x3):\n",
      " [[ 0.30471708 -1.03998411  0.7504512 ]\n",
      " [ 0.94056472 -1.95103519 -1.30217951]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "print(\"random normal (2x3):\\n\", rng.normal(size=(2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c464794",
   "metadata": {},
   "source": [
    "## Indexing conventions: row/column `(i, j)` vs `x, y`\n",
    "NumPy uses row, column `(i, j)` indexing:\n",
    "`arr[i, j]` means row `i`, column `j`.\n",
    "\n",
    "This is different from the `(x, y)` convention often used for plots or images, where `x` is the horizontal axis and `y` is the vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e6f71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "A[2, 1] = 10\n"
     ]
    }
   ],
   "source": [
    "A = np.arange(1, 13).reshape(3, 4)\n",
    "print(\"A =\\n\", A)\n",
    "\n",
    "# Row 2 (third row), column 1 (second column)\n",
    "print(\"A[2, 1] =\", A[2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfba0fe",
   "metadata": {},
   "source": [
    "## Axis Operations\n",
    "Many NumPy functions take an axis argument.\n",
    "\n",
    "axis=0 :  operate down the rows (collapse the row dimension)\n",
    "axis=1 : operate across columns for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4f62eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B =\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "sum over axis=0 (column‑wise): [5 7 9]\n",
      "sum over axis=1 (row‑wise): [ 6 15]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[1, 2, 3],\n",
    "                [4, 5, 6]])\n",
    "\n",
    "print(\"B =\\n\", B)\n",
    "print(\"sum over axis=0 (column‑wise):\", np.sum(B, axis=0))\n",
    "print(\"sum over axis=1 (row‑wise):\", np.sum(B, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836189d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min over axis=0: [1 2 3]\n",
      "argmax over axis=1: [2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"min over axis=0:\", np.min(B, axis=0))\n",
    "print(\"argmax over axis=1:\", np.argmax(B, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc09b13",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "Slicing lets us take sub‑arrays using the start:stop:step syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0f8172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr: [0 1 2 3 4 5 6 7 8 9]\n",
      "even indices arr[::2]: [0 2 4 6 8]\n",
      "reversed arr[::-1]: [9 8 7 6 5 4 3 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(10)\n",
    "print(\"arr:\", arr)\n",
    "print(\"even indices arr[::2]:\", arr[::2])\n",
    "print(\"reversed arr[::-1]:\", arr[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "466b60ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "rows 0..1, cols 1..3: \n",
      " [[2 3]\n",
      " [6 7]]\n",
      "column 2:  [ 3  7 11]\n"
     ]
    }
   ],
   "source": [
    "C = np.arange(1, 13).reshape(3, 4)\n",
    "print(\"C =\\n\", C)\n",
    "\n",
    "print(\"rows 0..1, cols 1..3: \\n\", C[0:2, 1:3])\n",
    "\n",
    "# all rows, column 2\n",
    "print(\"column 2: \", C[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f8eb5",
   "metadata": {},
   "source": [
    "### Boolean masking\n",
    "A mask is a boolean array we can use to filter another array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d8372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nums: [ 1  2  3  4  5  6  7  8  9 10]\n",
      "mask: [False  True False  True False  True False  True False  True]\n",
      "even numbers: [ 2  4  6  8 10]\n"
     ]
    }
   ],
   "source": [
    "nums = np.arange(1, 11)\n",
    "mask = (nums % 2 == 0)\n",
    "print(\"nums:\", nums)\n",
    "print(\"mask:\", mask)\n",
    "print(\"even numbers:\", nums[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be68af4",
   "metadata": {},
   "source": [
    "### Reshaping, transposing, expanding and squeezing\n",
    "Reshaping allows us to change the view of the data without copying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c354d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "\n",
      "reshaped to 4x5:\n",
      " [[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]]\n",
      "\n",
      "transpose (5x4):\n",
      " [[ 0  5 10 15]\n",
      " [ 1  6 11 16]\n",
      " [ 2  7 12 17]\n",
      " [ 3  8 13 18]\n",
      " [ 4  9 14 19]]\n"
     ]
    }
   ],
   "source": [
    "data = np.arange(20)\n",
    "print(\"data:\", data)\n",
    "\n",
    "M = data.reshape(4, 5)\n",
    "print(\"\\nreshaped to 4x5:\\n\", M)\n",
    "\n",
    "T = M.T\n",
    "print(\"\\ntranspose (5x4):\\n\", T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e2ff75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v shape: (3,)\n",
      "v_row shape: (1, 3)\n",
      "v_col shape: (3, 1)\n",
      "squeezed v_row shape: (3,)\n"
     ]
    }
   ],
   "source": [
    "v = np.array([1, 2, 3])\n",
    "print(\"v shape:\", v.shape)\n",
    "\n",
    "# Add a new axis at the front (1, 3)\n",
    "v_row = v[np.newaxis, :]\n",
    "print(\"v_row shape:\", v_row.shape)\n",
    "\n",
    "# Add a new axis at the end (3, 1)\n",
    "v_col = v[:, np.newaxis]\n",
    "print(\"v_col shape:\", v_col.shape)\n",
    "\n",
    "# Squeeze removes axes of length 1\n",
    "print(\"squeezed v_row shape:\", np.squeeze(v_row).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35a225",
   "metadata": {},
   "source": [
    "### Concatenation vs stacking\n",
    "- Concatenation joins arrays along an existing axis.\n",
    "- Stacking adds a new axis and then joins along that axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a =\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "b =\n",
      " [[5 6]\n",
      " [7 8]]\n",
      "\n",
      "concatenate along axis=0 (rows):\n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "\n",
      "concatenate along axis=1 (cols):\n",
      " [[1 2 5 6]\n",
      " [3 4 7 8]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2],\n",
    "                [3, 4]])\n",
    "b = np.array([[5, 6],\n",
    "                [7, 8]])\n",
    "\n",
    "print(\"a =\\n\", a)\n",
    "print(\"b =\\n\", b)\n",
    "\n",
    "print(\"\\nconcatenate along axis=0 (rows):\\n\", np.concatenate([a, b], axis=0))\n",
    "print(\"\\nconcatenate along axis=1 (cols):\\n\", np.concatenate([a, b], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a59c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack axis=0 shape: (2, 2, 2)\n",
      "stack axis=1 shape: (2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "stack0 = np.stack([a, b], axis=0)\n",
    "stack1 = np.stack([a, b], axis=1)\n",
    "\n",
    "print(\"stack axis=0 shape:\", stack0.shape)\n",
    "print(\"stack axis=1 shape:\", stack1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ed4a6",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "Broadcasting lets NumPy apply operations to arrays of different shapes when those shapes are compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbfd8320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row shape: (3,)\n",
      "col shape: (2, 1)\n",
      "\n",
      "col + row =\n",
      " [[11 12 13]\n",
      " [21 22 23]]\n",
      "result shape: (2, 3)\n"
     ]
    }
   ],
   "source": [
    "row = np.array([1, 2, 3])        # shape (3,)\n",
    "col = np.array([[10], [20]])     # shape (2, 1)\n",
    "\n",
    "print(\"row shape:\", row.shape)\n",
    "print(\"col shape:\", col.shape)\n",
    "\n",
    "result = col + row\n",
    "print(\"\\ncol + row =\\n\", result)\n",
    "print(\"result shape:\", result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a96df",
   "metadata": {},
   "source": [
    "### Elementwise vs matrix multiplication\n",
    "- `*` performs elementwise multiplication.\n",
    "- `@` performs matrix multiplication (linear algebra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74eb59f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =\n",
      " [[1 2]\n",
      " [3 4]]\n",
      "B =\n",
      " [[5 6]\n",
      " [7 8]]\n",
      "\n",
      "A * B (elementwise):\n",
      " [[ 5 12]\n",
      " [21 32]]\n",
      "\n",
      "A @ B (matrix multiply):\n",
      " [[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2],\n",
    "            [3, 4]])\n",
    "B = np.array([[5, 6],\n",
    "            [7, 8]])\n",
    "\n",
    "print(\"A =\\n\", A)\n",
    "print(\"B =\\n\", B)\n",
    "\n",
    "print(\"\\nA * B (elementwise):\\n\", A * B)\n",
    "print(\"\\nA @ B (matrix multiply):\\n\", A @ B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c15404",
   "metadata": {},
   "source": [
    "# 2. Revisiting PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b999dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.Tensor([[1,2],[3,4]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b8683",
   "metadata": {},
   "source": [
    "## Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a7314c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(device)\n",
    "    \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6ba40e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2413], device='cuda:0')\n",
      "tensor([-0.2413], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "# check if a CUDA device is available\n",
    "if torch.cuda.is_available():\n",
    "    #a CUDA device object \n",
    "    device = torch.device(\"cuda\")\n",
    "    # directly create y\n",
    "    x = x.to(device)\n",
    "    y = torch.ones_like(x, device=device)\n",
    "z = x + y\n",
    "print(z)\n",
    "print(z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db159e51",
   "metadata": {},
   "source": [
    "## Tensor to Numpy and back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9117f699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 5],\n",
       "       [2, 4, 6]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list = [[1, 3, 5],\n",
    "            [2, 4, 6]]\n",
    "\n",
    "x_tensor = torch.tensor(x_list)\n",
    "x_tensor\n",
    "x_np = x_tensor.numpy()\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2edf3ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 5],\n",
       "        [2, 4, 6]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.from_numpy(x_np)\n",
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b743354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor with all 0s\n",
    "zero_tensor = torch.zeros(2, 3)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c207d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor with all 1s\n",
    "\n",
    "ones_tensor = torch.ones(3, 3)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "574250a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.5000, 6.5000, 6.5000],\n",
       "        [6.5000, 6.5000, 6.5000],\n",
       "        [6.5000, 6.5000, 6.5000],\n",
       "        [6.5000, 6.5000, 6.5000]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor with specific value\n",
    "\n",
    "full_tensor = torch.full((4, 3), fill_value=6.5)\n",
    "full_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7201344f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7837, -0.3576, -0.7365],\n",
       "        [ 1.1453,  0.4480, -0.9496]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random tensor\n",
    "\n",
    "random_tensor = torch.randn(2, 3)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933605e0",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1302b",
   "metadata": {},
   "source": [
    "Lists are a foundational data structure in Python, allowing us to create simple and complex algorithms to solve problems. However, in mathematics and particularly in linear algebra, we work with vectors and matrices to model problems and create statistical solutions. Through the exercises in this section, we will begin introducing you to how to think more mathematically through the use of PyTorch by starting with a process known as vectorization.\n",
    "\n",
    "Index chasing is a very valuable skill, and certainly one you will need in this course, but mathematical problems often have simpler and more efficient representations that use vectors. The process of converting from an implimentation that uses indicies to one that uses vectors is known as vectorization. Once vectorized, the resulting implementation often yields to the user faster and more readable code than before.\n",
    "\n",
    "In the following problems in this section, we will ask you to practice reading mathematical expressions and deduce their vectorized equivalent along with their implementation in Python. You will use the PyTorch array object as the Python equivalent to a vector, and in later sections you will work with sets of vectors known as matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3599a2",
   "metadata": {},
   "source": [
    "We will consider two vectors $x$ and $y$ as follows for this section: \n",
    "\n",
    "$$\n",
    "\\mathbf{x} =\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n\n",
    "\\end{bmatrix},\n",
    "\\qquad\n",
    "\\mathbf{y} =\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46edee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  7,  8,  9, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# Non-vectorized\n",
    "for i in range(len(x)):\n",
    "    x[i] = x[i] + 5\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5fdfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  7,  8,  9, 10])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# Vectorized\n",
    "x = x + 5\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e3b6dd",
   "metadata": {},
   "source": [
    "The dot product of vectors x and y is defined as\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\cdot \\mathbf{y}\n",
    "= \\sum_{i=1}^n x_i y_i\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "x_1 & x_2 & \\cdots & x_n\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Your Task**: Implement the function `PYTORCH_dot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc156906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7082791)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "Y = torch.from_numpy(Y)\n",
    "\n",
    "print(X.dot(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b90d1e",
   "metadata": {},
   "source": [
    "## Outer Product\n",
    "\n",
    "\n",
    "The outer product (also known as the tensor product) of vectors x and y is defined as\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\otimes \\mathbf{y}\n",
    "\\;=\\;\n",
    "\\begin{bmatrix}\n",
    "x_1 y_1 & x_1 y_2 & \\cdots & x_1 y_n \\\\\n",
    "x_2 y_1 & x_2 y_2 & \\cdots & x_2 y_n \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "x_n y_1 & x_n y_2 & \\cdots & x_n y_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05a3fb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  59092, -144096,  136512,  ...,  -53088,  -86268,   53404],\n",
      "        [  82467, -201096,  190512,  ...,  -74088, -120393,   74529],\n",
      "        [-122111,  297768, -282096,  ...,  109704,  178269, -110357],\n",
      "        ...,\n",
      "        [-144551,  352488, -333936,  ...,  129864,  211029, -130637],\n",
      "        [-179707,  438216, -415152,  ...,  161448,  262353, -162409],\n",
      "        [  88825, -216600,  205200,  ...,  -79800, -129675,   80275]])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "Y = torch.from_numpy(Y)\n",
    "\n",
    "print(torch.outer(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63517d3",
   "metadata": {},
   "source": [
    "### Hadamard Product\n",
    "\n",
    "The Hadamard product (also known as the Schur product or element-wise product) of vectors x and y is defined as\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\odot \\mathbf{y} =\n",
    "\\begin{bmatrix}\n",
    "x_1 y_1 \\\\\n",
    "x_2 y_2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n y_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0cbd723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  59092, -201096, -282096,  ...,  129864,  262353,   80275])\n",
      "tensor([  59092, -201096, -282096,  ...,  129864,  262353,   80275])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "Y = torch.from_numpy(Y)\n",
    "\n",
    "print(X*Y)\n",
    "\n",
    "# or\n",
    "\n",
    "print(torch.mul(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d732012e",
   "metadata": {},
   "source": [
    "###  Sum-Product\n",
    "\n",
    "\n",
    "The sum-product of vectors x and y, each with n real component, is defined as\n",
    "\n",
    "$$\n",
    "f(x, y) =\n",
    "{\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "⋮\\\\\n",
    "1\n",
    "\\end{bmatrix}^{\\;T}\n",
    "%\n",
    "\\begin{bmatrix}\n",
    "x_1 y_1 & x_1 y_2 & … & x_1 y_n\\\\\n",
    "x_2 y_1 & x_2 y_2 & … & x_2 y_n\\\\\n",
    "⋮ & ⋮ & ⋱ & ⋮ \\\\\n",
    "x_n y_1 & x_n y_2 & … & x_n y_n\n",
    "\\end{bmatrix}\n",
    "%\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "⋮\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "} =\n",
    "\\displaystyle\\sum_{i=1}^{n} \\displaystyle\\sum_{j=1}^{n} x_i \\cdot y_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85796fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(265421520)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.randint(-1000, 1000, size=3000)\n",
    "Y = np.random.randint(-1000, 1000, size=3000)\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "Y = torch.from_numpy(Y)\n",
    "\n",
    "sum_product = torch.sum(X) * torch.sum(Y)\n",
    "print(sum_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23206a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  2   5 -10  -7]\n",
      "  [ -7  -3  -1   9]\n",
      "  [  8  -6  -4   2]]\n",
      "\n",
      " [[ -9  -4  -3   4]\n",
      "  [  7  -5   3  -2]\n",
      "  [ -1   9   6   9]]\n",
      "\n",
      " [[ -5   5   5 -10]\n",
      "  [  8  -7   7   9]\n",
      "  [  9   9   4  -3]]]\n",
      "tensor([  2,   5, -10,  -7,  -7,  -3,  -1,   9,   8,  -6,  -4,   2,  -9,  -4,\n",
      "         -3,   4,   7,  -5,   3,  -2,  -1,   9,   6,   9,  -5,   5,   5, -10,\n",
      "          8,  -7,   7,   9,   9,   9,   4,  -3])\n"
     ]
    }
   ],
   "source": [
    "# flatten tensor\n",
    "np.random.seed(0)\n",
    "X = np.random.randint(-10, 10, size=(3,3,4))\n",
    "print(X)\n",
    "X = torch.from_numpy(X)\n",
    "output_tensor = torch.flatten(X)\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07ae5685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before unsqueeze:  torch.Size([100, 100])\n",
      "Shape after unsqueeze:  torch.Size([1, 100, 100])\n",
      "tensor([[4, 4, 2,  ..., 2, 0, 1],\n",
      "        [1, 4, 4,  ..., 2, 1, 0],\n",
      "        [2, 4, 1,  ..., 4, 0, 3],\n",
      "        ...,\n",
      "        [2, 2, 3,  ..., 4, 2, 4],\n",
      "        [3, 4, 1,  ..., 1, 1, 0],\n",
      "        [0, 0, 2,  ..., 4, 2, 2]])\n",
      "tensor([[[4, 4, 2,  ..., 2, 0, 1],\n",
      "         [1, 4, 4,  ..., 2, 1, 0],\n",
      "         [2, 4, 1,  ..., 4, 0, 3],\n",
      "         ...,\n",
      "         [2, 2, 3,  ..., 4, 2, 4],\n",
      "         [3, 4, 1,  ..., 1, 1, 0],\n",
      "         [0, 0, 2,  ..., 4, 2, 2]]])\n"
     ]
    }
   ],
   "source": [
    "# Unsqueeze: unsqueeze function for torch tensors along given dimension.\n",
    "X = np.random.randint(0, 5, size=(100,100))\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "result = X.unsqueeze(dim=0)\n",
    "print(\"Shape before unsqueeze: \", X.shape)\n",
    "print(\"Shape after unsqueeze: \", result.shape)\n",
    "print(X)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12b85b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 6, 4, 6, 9]])\n",
      "tensor([1, 6, 4, 6, 9])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# squeeze: the squeeze function for torch tensors along axis with dimension 1 (i.e. axis = 0).\n",
    "X = np.random.randint(0, 10, size=(1,5))\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "\n",
    "result = X.squeeze(dim=0)\n",
    "\n",
    "print(X)\n",
    "print(result)\n",
    "print(X.shape)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf49e97f",
   "metadata": {},
   "source": [
    "###  Reshape\n",
    "\n",
    "\n",
    "$$\n",
    "X =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{2\\times3}\n",
    "\\quad\\Longrightarrow\\quad\n",
    "\\operatorname{reshape}(X, (3, 2)) =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{3\\times2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "22c55c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 0, 3],\n",
      "        [3, 7, 9]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[5, 0],\n",
      "        [3, 3],\n",
      "        [7, 9]])\n",
      "torch.Size([3, 2])\n",
      "===============\n",
      "tensor([[3, 5, 2, 4, 7, 6, 8, 8, 1, 6],\n",
      "        [7, 7, 8, 1, 5, 9, 8, 9, 4, 3],\n",
      "        [0, 3, 5, 0, 2, 3, 8, 1, 3, 3]])\n",
      "torch.Size([3, 10])\n",
      "tensor([[[3, 5, 2, 4, 7],\n",
      "         [6, 8, 8, 1, 6],\n",
      "         [7, 7, 8, 1, 5]],\n",
      "\n",
      "        [[9, 8, 9, 4, 3],\n",
      "         [0, 3, 5, 0, 2],\n",
      "         [3, 8, 1, 3, 3]]])\n",
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.randint(0, 10, size=(2,3))\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "result = X.reshape((3,2))\n",
    "print(result)\n",
    "print(result.shape)\n",
    "\n",
    "X = np.random.randint(0, 10, size=(3,10))\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "\n",
    "print(\"===============\")\n",
    "print(X)\n",
    "print(X.shape)\n",
    "\n",
    "result = X.reshape((2,3, 5))\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e0961f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 6, 7],\n",
      "        [2, 0, 3]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[3, 2],\n",
      "        [6, 0],\n",
      "        [7, 3]])\n",
      "torch.Size([3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2],\n",
       "        [6, 0],\n",
       "        [7, 3]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose\n",
    "X = np.random.randint(0, 10, size=(2,3))\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "\n",
    "print(X)\n",
    "print(X.shape)\n",
    "result = X.T\n",
    "print(result)\n",
    "print(result.shape)\n",
    "\n",
    "#or\n",
    "torch.transpose(X, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a34b02ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 3, 4])\n",
      "Permuted shape: torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Permute: rearrange the dimensions of a tensor according to a specified new order.\n",
    "# Create a tensor of size (2, 3, 4)\n",
    "original_tensor = torch.randn(2, 3, 4)\n",
    "print(f\"Original shape: {original_tensor.shape}\")\n",
    "\n",
    "# Permute the dimensions to the order (2, 0, 1)\n",
    "# The dimension at index 2 moves to 0\n",
    "# The dimension at index 0 moves to 1\n",
    "# The dimension at index 1 moves to 2\n",
    "permuted_tensor = original_tensor.permute(2, 0, 1)\n",
    "print(f\"Permuted shape: {permuted_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8d9e5830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (dim=0): torch.Size([2, 2, 2])\n",
      "Shape (dim=1): torch.Size([2, 2, 2])\n",
      "Shape (dim=2): torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# stacking\n",
    "\n",
    "import torch\n",
    "\n",
    "tensor_A = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor_B = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Stack along a new dimension at the start (dim=0)\n",
    "stacked_tensor_0 = torch.stack((tensor_A, tensor_B), dim=0)\n",
    "print(\"Shape (dim=0):\", stacked_tensor_0.shape)\n",
    "# Output: Shape (dim=0): torch.Size([2, 2, 2])\n",
    "\n",
    "# Stack along a new dimension in the middle (dim=1)\n",
    "stacked_tensor_1 = torch.stack((tensor_A, tensor_B), dim=1)\n",
    "print(\"Shape (dim=1):\", stacked_tensor_1.shape)\n",
    "# Output: Shape (dim=1): torch.Size([2, 2, 2])\n",
    "\n",
    "# Stack along a new dimension at the end (dim=2)\n",
    "stacked_tensor_2 = torch.stack((tensor_A, tensor_B), dim=2)\n",
    "print(\"Shape (dim=2):\", stacked_tensor_2.shape)\n",
    "# Output: Shape (dim=2): torch.Size([2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f00a3",
   "metadata": {},
   "source": [
    "### Padding\n",
    "\n",
    "- Input shape: (5, 10) — 5 rows, 10 columns\n",
    "- Output shape: (10, 11) — 10 rows (5 + 3 top + 2 bottom), 11 columns (10 + 0 left + 1 right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab2fc310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1373, 0.5843, 0.7626, 0.1079, 0.1356, 0.9114, 0.7032, 0.5586, 0.5222,\n",
      "         0.0304],\n",
      "        [0.3062, 0.7166, 0.2269, 0.3424, 0.7344, 0.6181, 0.2086, 0.6008, 0.2953,\n",
      "         0.8424],\n",
      "        [0.7688, 0.8410, 0.8325, 0.4508, 0.3418, 0.8518, 0.3898, 0.1558, 0.4692,\n",
      "         0.6618],\n",
      "        [0.1105, 0.6102, 0.1921, 0.3424, 0.0924, 0.9672, 0.0456, 0.3750, 0.3568,\n",
      "         0.9051],\n",
      "        [0.4316, 0.0884, 0.3531, 0.1734, 0.3874, 0.5023, 0.2440, 0.2403, 0.0146,\n",
      "         0.5062]])\n",
      "torch.Size([5, 10])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1373, 0.5843, 0.7626, 0.1079, 0.1356, 0.9114, 0.7032, 0.5586, 0.5222,\n",
      "         0.0304, 0.0000],\n",
      "        [0.3062, 0.7166, 0.2269, 0.3424, 0.7344, 0.6181, 0.2086, 0.6008, 0.2953,\n",
      "         0.8424, 0.0000],\n",
      "        [0.7688, 0.8410, 0.8325, 0.4508, 0.3418, 0.8518, 0.3898, 0.1558, 0.4692,\n",
      "         0.6618, 0.0000],\n",
      "        [0.1105, 0.6102, 0.1921, 0.3424, 0.0924, 0.9672, 0.0456, 0.3750, 0.3568,\n",
      "         0.9051, 0.0000],\n",
      "        [0.4316, 0.0884, 0.3531, 0.1734, 0.3874, 0.5023, 0.2440, 0.2403, 0.0146,\n",
      "         0.5062, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]])\n",
      "torch.Size([10, 11])\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "\n",
    "import torch.nn.functional as F\n",
    "source = torch.rand((5,10))\n",
    "print(source)\n",
    "print(source.shape)\n",
    "result = F.pad(input=source, pad=(0, 1, 3, 2), mode='constant', value=0)\n",
    "print(result)\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5991d",
   "metadata": {},
   "source": [
    "## Automatic Differentiation (Autograd) Basics\n",
    "\n",
    "Automatic differentiation is a technique where the computer automatically calculates derivatives (gradients) of our functions for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97468a0",
   "metadata": {},
   "source": [
    "### Calculating gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b33b46a",
   "metadata": {},
   "source": [
    "Let's take the equation: $\n",
    "y = x^2\n",
    "$\n",
    "\n",
    "Differentiating $y$ w.r.t $x$,\n",
    "$\n",
    "\\frac{dy}{dx} = 2x\n",
    "$\n",
    "\n",
    "At $x = 2$, we have $\\frac{dy}{dx} = 2\\cdot 2 = 4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52c77bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx (x.grad): 4.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()\n",
    "\n",
    "print(f\"dy/dx (x.grad): {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab06317",
   "metadata": {},
   "source": [
    "`requires_grad=True` tells PyTorch to track operations on that tensor so it can compute and store gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ed54b",
   "metadata": {},
   "source": [
    "Let's take another example: $\n",
    "y = a^2 + c\\,b.\n",
    "$\n",
    "\n",
    "Then\n",
    "$\n",
    "\\frac{\\partial y}{\\partial a} = 2a\\qquad\n",
    "\\frac{\\partial y}{\\partial c} = b\\qquad\n",
    "\\frac{\\partial y}{\\partial b} = c\n",
    "$\n",
    "\n",
    "\n",
    "At $a = 2$, $b = 4$, $c = 3$, the gradients are:\n",
    "\n",
    "$\n",
    "\\frac{\\partial y}{\\partial a} = 2a = 2 \\cdot 2 = 4\n",
    "$\n",
    "\n",
    "$\n",
    "\\frac{\\partial y}{\\partial c} = b = 4\n",
    "$\n",
    "\n",
    "$\n",
    "\\frac{\\partial y}{\\partial b} = c = 3\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eb1f4a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/da (a.grad): tensor(4.)\n",
      "dy/dc (c.grad): tensor(4.)\n",
      "dy/db (b.grad): None\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(4.0) # Notice that we are not setting requires_grad to True\n",
    "c = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "y = a**2 + c * b\n",
    "y.backward()\n",
    "\n",
    "print(\"dy/da (a.grad):\", a.grad)\n",
    "print(\"dy/dc (c.grad):\", c.grad)\n",
    "print(\"dy/db (b.grad):\", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec28563",
   "metadata": {},
   "source": [
    "In the above code cell we set `a.requires_grad = True`, `b.requires_grad = False` (default), and `c.requires_grad = True`,  \n",
    "so autograd only keeps the gradients\n",
    "$\n",
    "\\frac{\\partial y}{\\partial a} = 2a\n",
    "$ and $\n",
    "\\frac{\\partial y}{\\partial c} = b,\n",
    "$\n",
    "and does not store a gradient for $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "da3217b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/da (a.grad): tensor(4.)\n",
      "dy/dc (c.grad): tensor(4.)\n",
      "dy/db (b.grad): tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(4.0, requires_grad=True) # Notice that now we are setting requires_grad to True and we will get the gradient for this tensor\n",
    "c = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "y = a**2 + c * b\n",
    "y.backward()\n",
    "\n",
    "print(\"dy/da (a.grad):\", a.grad)\n",
    "print(\"dy/dc (c.grad):\", c.grad)\n",
    "print(\"dy/db (b.grad):\", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d6cb3a",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e5a16232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial C/partial w1: -1.0\n"
     ]
    }
   ],
   "source": [
    "# 2. Automatic Differentiation in Pytorch to find Partial Derivative\n",
    "import torch\n",
    "\n",
    "# Define input values with requires_grad=True to track gradients\n",
    "w1 = torch.tensor(2.0, requires_grad=True)  # w_1 = w\n",
    "x1 = torch.tensor(1.0, requires_grad=False) # x_1 = x\n",
    "b1 = torch.tensor(1.0, requires_grad=False) # b_1 = b\n",
    "y1 = torch.tensor(5.0, requires_grad=False) # y_1 = y\n",
    "\n",
    "# Compute intermediate variables\n",
    "w2 = w1 * x1\n",
    "w3 = w2 + b1\n",
    "w4 = torch.max(torch.tensor(0.0), w3)\n",
    "w5 = y1 - w4\n",
    "C = w5  # C = result\n",
    "\n",
    "# Compute gradients\n",
    "C.backward()\n",
    "\n",
    "# Print the gradient of C with respect to w1\n",
    "print(\"partial C/partial w1:\", w1.grad.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b3c02092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([27., 12.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([3.0, 2.0], requires_grad=True)\n",
    "y = x**3  # y = [27, 8]\n",
    "\n",
    "# This tells PyTorch: treat each output element equally (weight = 1)\n",
    "y.backward(gradient=torch.ones_like(y))\n",
    "print(x.grad)  # tensor([27., 12.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db2360",
   "metadata": {},
   "source": [
    "###  Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc34f5",
   "metadata": {},
   "source": [
    "PyTorch builds a graph (called computation graph) of all the tensor operations that led to the final tensor (like `y`).\n",
    "`grad_fn` links that tensor to the last operation that created it.\n",
    "By walking this graph backwards, PyTorch automatically computes gradeint for all tensors with `requires_grad=True` - Makes life so easier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30ce9f",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "214fb99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.grad_fn: <AddBackward0 object at 0x7f1409d39e70>\n",
      "y.grad_fn.next_functions:\n",
      "  (<PowBackward0 object at 0x7f12f7207e20>, 0)\n",
      "  (<MulBackward0 object at 0x7f1409d39e70>, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"y.grad_fn:\", y.grad_fn)\n",
    "print(\"y.grad_fn.next_functions:\")\n",
    "for nf in y.grad_fn.next_functions:\n",
    "    print(f\"  {nf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d558c",
   "metadata": {},
   "source": [
    "### Caution: Gradients accumulate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4be7ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: dy/dx (x.grad) = 4.0\n",
      "Step 2: dy/dx (x.grad) = 8.0\n",
      "Step 3: dy/dx (x.grad) = 12.0\n",
      "Step 4: dy/dx (x.grad) = 16.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "for step in range(4):\n",
    "    y = x**2\n",
    "    y.backward() # dy/dx = 2x = 4; added to x.grad\n",
    "    print(f\"Step {step+1}: dy/dx (x.grad) = {x.grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb1c23",
   "metadata": {},
   "source": [
    "By default, `.backward()` accumulates gradients into `x.grad` (or any tensor) instead of replacing them. So, in the above code cell, each call to `y.backward()` computes $4$ and adds it to the existing `x.grad`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa521477",
   "metadata": {},
   "source": [
    "To avoid gradient getting accumulated, we clear the gradient first so that each step uses only the gradient from the current computation, not leftovers from previous steps.\n",
    "\n",
    "So, we will reset `x.grad` to $0$. before each `.backward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "be2395ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: dy/dx (x.grad) = 4.0\n",
      "Step 2: dy/dx (x.grad) = 4.0\n",
      "Step 3: dy/dx (x.grad) = 4.0\n",
      "Step 4: dy/dx (x.grad) = 4.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "for step in range(4):\n",
    "  if x.grad is not None:\n",
    "    x.grad.zero_() # Resets the gradient to 0\n",
    "  y = x**2\n",
    "  y.backward() # Then .backward() computes 4 and adds it to 0\n",
    "  print(f\"Step {step+1}: dy/dx (x.grad) = {x.grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd19af",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "\\text{Forward Pass:} & \\quad \\hat{y} = \\max(0, XW_1)W_2 \\\\\n",
    "\\text{Loss Function:} & \\quad L = \\sum_{i=1}^{N} \\|\\hat{y}_i - y_i\\|^2 \\\\\n",
    "\\text{Update Rule:} & \\quad W_{new} = W_{old} - \\eta \\nabla_W L\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "46f7aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100: 479.1273498535156\n",
      "Iteration 200: 2.293727397918701\n",
      "Iteration 300: 0.01633179560303688\n",
      "Iteration 400: 0.0003115051658824086\n",
      "Iteration 500: 4.3086962250526994e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define dimensions\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors; setting requires_grad=True tracks the computational graph\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "w1 = torch.randn(D_in, H, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y using operations on Tensors\n",
    "    # .clamp(min=0) is the ReLU activation function\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(f\"Iteration {t+1}: {loss.item()}\")\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    # This computes the gradient of loss with respect to all Tensors with requires_grad=True.\n",
    "    loss.backward()\n",
    "\n",
    "    # Manually update weights using gradient descent. \n",
    "    # Wrap in torch.no_grad() because weights have requires_grad=True, \n",
    "    # but we don't need to track this step in autograd.\n",
    "    with torch.no_grad():\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3582e4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. Forward Pass\n",
    "The model computes the prediction $\\hat{y}$ through a hidden layer with a ReLU activation:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h &= XW_1 \\\\\n",
    "a &= \\max(0, h) \\\\\n",
    "\\hat{y} &= aW_2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### 2. Loss Function\n",
    "The objective is to minimize the Sum of Squared Errors (SSE):\n",
    "\n",
    "$$L = \\sum (\\hat{y} - y)^2$$\n",
    "\n",
    "### 3. Backward Pass (Gradients)\n",
    "We use the chain rule to find the partial derivatives for our weights.\n",
    "\n",
    "**Gradient for $W_2$:**\n",
    "$$\\frac{\\partial L}{\\partial W_2} = a^T \\cdot 2(\\hat{y} - y)$$\n",
    "\n",
    "**Gradient for $W_1$:**\n",
    "First, we calculate the error backpropagated through the second layer:\n",
    "$$\\delta_{out} = 2(\\hat{y} - y)W_2^T$$\n",
    "\n",
    "Then, we account for the ReLU derivative:\n",
    "$$\\frac{\\partial L}{\\partial W_1} = X^T \\cdot (\\delta_{out} \\odot \\mathbb{I}(h > 0))$$\n",
    "\n",
    "*Note: $\\odot$ denotes element-wise multiplication and $\\mathbb{I}$ is the indicator function.*\n",
    "\n",
    "### 4. Update Rule\n",
    "Using Gradient Descent with learning rate $\\eta$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W_1 &\\leftarrow W_1 - \\eta \\frac{\\partial L}{\\partial W_1} \\\\\n",
    "W_2 &\\leftarrow W_2 - \\eta \\frac{\\partial L}{\\partial W_2}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
